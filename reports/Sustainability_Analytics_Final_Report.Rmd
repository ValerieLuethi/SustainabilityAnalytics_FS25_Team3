---
title: "Sustainability Analytics: Project Report Group 2"
subtitle: "Effect of Climate Change on Great Aletsch Glacier and the village of Brig"
author:
  - name: "Vani Gupta"
    affiliation: "Hochschule Luzern"
    email: "vani.gupta@stud.hslu.ch"
  - name: "Ramona Kölliker"
    affiliation: "Hochschule Luzern"
    email: "ramona.kölliker@stud.hslu.ch"
  - name: "Valérie Lüthi"
    affiliation: "Hochschule Luzern"
    email: "valerie.lüthi@stud.hslu.ch"
  - name: "Alois Wagner"
    affiliation: "Hochschule Luzern"
    email: "alois.wagner@stud.hslu.ch"
date: "2025-09-05"
output:
  html_document:
    number_sections: true
    theme: lumen
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    toc-title: Table of Content
  minidown::mini_document:
    result_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<u>**Loading R-Packages**</u>
```{r Loading_Packages, include=TRUE, warning=FALSE, message=FALSE, echo=TRUE, results='hide'}
#Loading needed packages
library(dplyr)
library(forecast)
library(ggplot2)
library(lubridate)
library(tidyr)
library(tseries)  # for working with time series
library(ismev)    # for EVT gev.fit
library(tidyverse)# for data handling (includes ggplot2, dplyr, tidyr, readr, lubridate)
library(evd)      # for calculating HQ values in EVT
library(zoo)      # for function 'yearmon'
```

# Introduction (Ramona)

<br><p style="font-size: 35px;"> Introduction </p><br>

Hinweis für Ramona: Falls wir für die Einleitung oder Abstrakt keine Auflistung im Inhaltsverzeichnis haben möchten, könnten wir das mit **'p style="font-size: 35px;"> Introduction </p'** anstelle von **## Introduction** lösen.


# Datapreparation/Cleaning

The [feature explanation](#Table_feature_exp) can be found in the appendix.

<u>**Loading Data**</u>
```{r loading_data, include= TRUE, echo=TRUE}
# Reading in data
# for massa, rhone: why are the processed csv loaded instead of the raw data?
raw_massa <- read.csv('../data/processed/massa_cleaned.csv', header=TRUE, sep=',', na.strings='-')
raw_rhone <- read.csv('../data/processed/rhone_cleaned.csv', header=TRUE, sep=',', na.strings='-')
raw_glacier <- read.csv('../data/raw/massbalance_observation.csv', header=TRUE, sep=';', na.strings='-')
raw_jungfraujoch <- read.csv("../data/raw/weather_monthly_jungfraujoch.csv", header=TRUE, sep=';', na.strings='-')
raw_brigrain <- read.csv('../data/raw/weather_rain_monthly_brig.csv', header=TRUE, sep=';', na.strings='-')
```


## Jungfraujoch Temperature
The homogeneous data series from the Jungfraujoch climate station is available on demand via [MeteoSchweiz OpenData](https://www.meteoswiss.admin.ch/services-and-publications/service/open-data.html). The station is located 3571 meters above sea level and located in the Aletsch area. We were interested in the measurement of the homogeneous monthly mean temperature covering the time span from 01/01/1933 to 01/07/2025. The temperature in Celsius was measured 2 meters above ground.

The raw Jungfraujoch weather data set was prepared by first converting the reference_timestamp column into a proper datetime format. Then the data set was reduced to the columns necessary for our analysis (station_abbr, reference_timestamp, temp_mean_C). For clarity columns were renamed. A check for missing values, confirmed that there were none. Finally a time series object of the mean temperature values was created, specifying the start and end dates as well as the monthly frequency. 
```{r jungfraujoch_temperature_data_preparation, include = TRUE}
# convert timestamp to datetime format
df_jungfraujoch <- raw_jungfraujoch %>%
  mutate(reference_timestamp = dmy_hm(reference_timestamp))
# only keep columns needed for analysis
df_jungfraujoch_reduced <- df_jungfraujoch %>% 
  select(station_abbr, reference_timestamp, ths200m0)
# rename columns
colnames(df_jungfraujoch_reduced) <- c('station_abbr', 'reference_timestamp', 'temp_mean_C')
# check for NAs
colSums(is.na(df_jungfraujoch_reduced)) # no NAs
```

## Glacier
The data is sourced from Glacier Monitoring in Switzerland (GLAMOS). Direct measurements of glacier mass balance – the sum of snow accumulation and snow/ice melt – are carried out on selected glaciers in Switzerland, based on point observations, typically acquired in April/May and September. 
For clarity, unnecessary columns were removed and the others were renamed. We were interested in information specifically regarding "Grosser Aletschgletscher" hence the dataset was filtered to just the relevant rows. We converted the date columns into proper datetime format. A check for missing values, confirmed that there were none.

```{r glacier_data_preparation, include = TRUE, echo = TRUE}
## remove unwanted columns
df_glacier <- raw_glacier %>% 
  select(-c("glacier.id", "observer", "X", "X.1", "X.2", "minimum.elevation.of.glacier", "maximum.elevation.of.glacier" ))
## rename columns to standard format
colnames(df_glacier) <- c("glacier_name", "obs_start_date", "obs_winter_end_date", "obs_end_date", "winter_mass_balance_mmwe",
                          "summer_mass_balance_mmwe", "annual_mass_balance_mmwe","equilibrium_line_altitude_m", 
                          "accumulation_area_ratio", "glacier_area_m2")
## filter out rows of unwanted glaciers
df_glacier <- df_glacier %>%
  filter(glacier_name == "Grosser Aletschgletscher")
## convert relevant columns to date type values
df_glacier <- df_glacier %>%
  mutate(across(c(obs_start_date, obs_winter_end_date, obs_end_date), 
                ~ as.Date(.x, format = "%d.%m.%Y")))
## check for NAs
colSums(is.na(df_glacier))
```

In order to perform correlation analysis, the bi-annual mass balance values were extrapolated to monthly values using weighted averages derived from the Jungfraujoch temperature data. 

```{r glacier_monthly_data_preparation, include = TRUE, echo = TRUE}

## Function to allocate seasonal mass balance by fixed calendar seasons
allocate_mass_balance_per_year <- function(row, df_jungfraujoch_reduced){
  
  obs_year <- year(row$obs_start_date)  # Observation year for this glacier row
  # Add helper columns
  df_jungfraujoch_reduced <- df_jungfraujoch_reduced %>%
    mutate(
      year_num = year(reference_timestamp),
      month_num = month(reference_timestamp),
      year_month = format(reference_timestamp, "%Y-%m"),
      temp_mean_C = as.numeric(temp_mean_C)
    )
  
  ## Winter months: Oct–Dec from previous year, Jan–Apr from current observation year
  winter_climate <- df_jungfraujoch_reduced %>%
    filter((month_num %in% 10:12 & year_num == (obs_year - 1)) |
             (month_num %in% 1:4 & year_num == obs_year))
  
  winter_weights <- abs(winter_climate$temp_mean_C)
  if(sum(winter_weights) == 0) winter_weights <- rep(1/nrow(winter_climate), nrow(winter_climate))
  winter_weights <- winter_weights / sum(winter_weights)
  winter_alloc <- winter_weights * row$winter_mass_balance_mmwe
  
  ## Summer months: May–Sep of current observation year
  summer_climate <- df_jungfraujoch_reduced %>%
    filter(month_num %in% 5:9 & year_num == obs_year)
  
  summer_weights <- abs(summer_climate$temp_mean_C)
  if(sum(summer_weights) == 0) summer_weights <- rep(1/nrow(summer_climate), nrow(summer_climate))
  summer_weights <- summer_weights / sum(summer_weights)
  summer_alloc <- summer_weights * row$summer_mass_balance_mmwe
  
  ## Combine summer and winter calculations
  dates <- c(winter_climate$year_month, summer_climate$year_month)
  alloc <- c(winter_alloc, summer_alloc)
  
  ## Return monthly allocation
  data.frame(
    year_month = dates,
    month = c(winter_climate$month_num, summer_climate$month_num),
    mass_balance_monthly = alloc
  )
}

## Construct df_glacier_monthly
df_glacier_monthly <- bind_rows(lapply(1:nrow(df_glacier), function(i){
  allocate_mass_balance_per_year(df_glacier[i, ], df_jungfraujoch_reduced)
}))

head(df_glacier_monthly,20)
```

## River Massa (Ramona)

## Brig Rain

```{r brig_rain_data_preparation, include = TRUE}
raw_brigrain$Date <- as.Date(raw_brigrain$reference_timestamp, format = "%d.%m.%Y")

df_rain <- raw_brigrain %>% select(Date, rhs150m0)
#plot(df_rain)

# defining starting year and month
start_year_brig  <- year(min(df_rain$Date))
start_month_brig <- month(min(df_rain$Date))
```



# Exploratory Data Analysis (Vani)

### Temperature
```{r jungfraujoch_temperature_data_exploration, include = TRUE}
ts_temp <- ts(df_jungfraujoch_reduced$temp_mean_C,
              start = min(df_jungfraujoch_reduced$reference_timestamp),
              frequency = 12)   # monthly data (12 obs per year)

str(ts_temp)
summary(ts_temp)

# Plot observed temp with LOWESS trend
plot(ts_temp,
     ylab = "Observed Temperature (°C)",
     xlab = "Year",
     col = "blue", lwd = 1,
     main = "Observed Jungfrau Temperature")

# Add smoothed trend line
lines(lowess(time(ts_temp), ts_temp), col = "red", lwd = 2)

```
A look at the summary statistics reveals that monthly mean temperatures at Jungfraujoch are predominantly below freezing, ranging from extremely cold (-21.7 C°) to just above freezing (3.5 C°). This is consistent with the high-altitude alpine climate.
The plot of monthly mean temperatures shows clear seasonal oscillations, with cold winters and milder summers. There is also a slight upward trend, suggesting that the mean temperatures might increase gradually over the years. This could hint at the climate getting warmer.

# Stationarity

## Temperature Jungfraujoch

### Stationarity
We further check the stationarity of the time series by inspecting the ACF and PACF. The ACF shows a strong seasonal pattern reflecting the annual temperature cycle. The PACF indicates that monthly mean temperatures are influenced by the previous month (lag 1). Then shows a negative connection for the next few months (lags 2 to 6) and a positive connection again (lags 8 to 13). This is likely due to temperature changes following a seasonal pattern, where each month corresponds to a specific period (e.g. season). 
<u>**Jungfraujoch ACF and PACF**</u>
```{r jungfraujoch_temperature_acf_pacf, include = TRUE}
# create time series object
# temp_mean monthly series
ts_jungfraujoch <- ts(df_jungfraujoch_reduced$temp_mean_C,
                      start = c(1933, 1),
                      end = c(1933 + (nrow(df_jungfraujoch_reduced)-1) %/% 12,
                              (nrow(df_jungfraujoch_reduced)-1) %% 12 + 1),
                      frequency = 12)

# acf and pacf
acf(ts_jungfraujoch) # acf indicates seasonality
pacf(ts_jungfraujoch) # damped sinusoid
```
To further analyze the time series, we applied Seasonal-Trend decomposition using Loess (STL). STL separates the time series into trend, seasonal and remainder components, which is useful to identify and remove sesanality and trends before time series modelling. Different variations of the s.window parameter were tested to control the smoothness of the seasonal component. Additionaly the t.window parameter was used to control the smoothing of the trend component. We observed that larger seasonal windows slightly reduced autocorrelations in the remainder, whereas the PACF improved notably when using a large trend window. An s.window of 37 and a t.window of 121 showed the most satisfying result.
The Augmented-Dickey-Fuller test was used to formally check stationarity of the remainder. The significant result (p < .01) indicates stationarity.
<u>**Jungfraujoch Temperature STL Decomposition**</u>
```{r jungfraujoch_temperature_stl_decomposition, include = TRUE}
# decomposition with stl
ts_jungfraujoch_stl <- stl(ts_jungfraujoch, s.window = "periodic") # assumes strong, stable seasonality
plot(ts_jungfraujoch_stl, main = "s.window periodic")
ts_jungfraujoch_stl_13 <- stl(ts_jungfraujoch, s.window = 13) # 1 year smooth
plot(ts_jungfraujoch_stl_13, main = "s.window = 13")
ts_jungfraujoch_stl_25 <- stl(ts_jungfraujoch, s.window = 25) # 2 year smooth
plot(ts_jungfraujoch_stl_25, main = "s.window = 25")
ts_jungfraujoch_stl_37 <- stl(ts_jungfraujoch, s.window = 37) # 3 year smooth
plot(ts_jungfraujoch_stl_37, main = "s.window = 37")
ts_jungfraujoch_stl_37_121 <- stl(ts_jungfraujoch, s.window = 37, t.window=121) # 3 year smooth
plot(ts_jungfraujoch_stl_37_121, main = "s.window = 37, t.window=121")
ts_jungfraujoch_stl_49 <- stl(ts_jungfraujoch, s.window = 49)
plot(ts_jungfraujoch_stl_49)

remainder_periodic <- ts_jungfraujoch_stl$time.series[, "remainder"]
acf(remainder_periodic, main = "ACF of STL remainder, periodic")
pacf(remainder_periodic, main = "PACF of STL remainder, periodic")

remainder_13 <- ts_jungfraujoch_stl_13$time.series[, "remainder"]
acf(remainder_13, main = "ACF of STL remainder, s.window = 13")
pacf(remainder_13, main = "PACF of STL remainder, s.window = 13")

remainder_25 <- ts_jungfraujoch_stl_25$time.series[, "remainder"]
acf(remainder_25, main="ACF of STL remainder, s.window = 25")
pacf(remainder_25, main = "PACF of STL remainder, s.window = 25")

remainder_37 <- ts_jungfraujoch_stl_37$time.series[, "remainder"]
acf(remainder_37, main = "ACF of STL remainder, s.window = 37") # ACF lags 2 and 5 persist
pacf(remainder_37, main = "PACF of STL remainder, s.window = 37")

remainder_37_121 <- ts_jungfraujoch_stl_37_121$time.series[, "remainder"]
acf(remainder_37_121)
pacf(remainder_37_121) # no change compared to without t.window

# augmented dickey fuller test to check stationarity formally
adf.test(remainder_37_121)
```
For further modelling a data frame containing the components of the decomposed time series as well as the observed data was created and saved.
<u>**Jungfraujoch create cleaned data frame**</u>
```{r jungfraujoch_temperature_clean_df, include = TRUE}
# Extract components
components <- ts_jungfraujoch_stl_37_121$time.series
# Create a time index (Date or Year-Month depending on your ts object)
dates <- time(ts_jungfraujoch)
# Build a data frame
df_jungfraujoch_processed <- data.frame(
  date       = dates,
  observed   = as.numeric(ts_jungfraujoch),
  trend      = as.numeric(components[, "trend"]),
  seasonal   = as.numeric(components[, "seasonal"]),
  remainder  = as.numeric(components[, "remainder"])
)
# create processed data file
write.csv(df_jungfraujoch_processed, "../data/processed/jungfraujoch_temperature.csv", row.names = FALSE)
# RDS
saveRDS(df_jungfraujoch_processed, "../data/processed/jungfraujoch_temperature.rds")
```

## Rainfall Brig (Alois)

### Stationarity with stl

<u>**Brig rain stl**</u>
```{r brig_rain_stl, include = TRUE}
# creating ts-object on a monthly basis
rain_ts <- ts(df_rain$rhs150m0,
              start = c(start_year_brig, start_month_brig),
              frequency = 12)   # 12 month per year
stl_1 <- stl(rain_ts, s.window =122, t.window=115)
plot(stl_1)
remainder_stl1 <- stl_1$time.series[,"remainder"]
adf.test(remainder_stl1)
acf(remainder_stl1, main = "ACF of residuals / Brig Rain / stl")
pacf(remainder_stl1, main = "PACF of residuals / Brig Rain / stl")
```

<u>**Brig creating dataframe with stl prepared data**</u>
```{r brig_rain_dataframe_stl, include = TRUE}
#Creating dataframe of the prepared data
rain_decomp_df <- data.frame(
  Date      = as.Date(as.yearmon(time(rain_ts))),  # month data
  Original  = as.numeric(rain_ts),                 # Raw Data
  Trend     = stl_1$time.series[,"trend"],         # Trend-Componente
  Seasonal  = stl_1$time.series[,"seasonal"],      # Saisonal-Component
  Remainder = stl_1$time.series[,"remainder"]      # Remainder
)

head(rain_decomp_df)  # for checking

#saveRDS(rain_decomp_df, file = "rain_decomposition.rds")
```




## River Massa
### Waterlevel (Ramona)


## River Rhone
### Waterlevel (Ramona)

### Watervolume (Alois)

<u>**watervolume Data Preparation**</u>
```{r watervolume_massa_preparation, echo=FALSE}
# Read data
df_massa <- raw_massa

## Time Series Massa River - daily data
freq_daily <- 365.2422

ts_watervolume_massa <- ts(df_massa$discharge_vol_m3s, 
              start = c(year(min(df_massa$date_yyyymmdd)),
                        yday(min(df_massa$date_yyyymmdd))), 
              frequency = freq_daily)


# creating dataframe out of ts_watervolume_massa
#----------------------------
# defining start date
massa_start_date <- as.Date("1981-01-01")
# length of time series
n <- length(ts_watervolume_massa)
# creating date
massa_dates <- seq.Date(from = massa_start_date, by = "day", length.out = n)

df_massa_prep <- data.frame(
  Date = massa_dates,
  Watervolume = ts_watervolume_massa
)

#----------------------------------------------------------------------
#----------------------------------------------------------------------
#First insights of massa data / creating ts

#plotting massa data / watervolume
#plot(ts_watervolume_massa, main = "Massa daily discharge volume in m³/s 1980 - 2020")
```

#### Monthly average Massa

<u>**Creating monthly average values for massa**</u>
```{r monthly_average_massa, include = TRUE}
# calculation average monthly watervolume
df_massa_monthly <- df_massa %>%
  mutate(Year = year(date_yyyymmdd),
         Month = month(date_yyyymmdd)) %>%
  group_by(Year, Month) %>%
  summarise(
    discharge_monthly_mean = mean(discharge_vol_m3s, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(Date = as.Date(paste(Year, Month, "01", sep = "-")))
  
## Time Series Massa River - monthly data
ts_watervolume_monthly <- ts(df_massa_monthly$discharge_monthly_mean, 
              start = c(year(min(df_massa_monthly$Date)),
                        month(min(df_massa_monthly$Date))), 
              frequency = 12)


plot(ts_watervolume_monthly, main = "Massa mean discharge volume in m³/s 1980 - 2020")
```

##### Stationarity with stl

<u>**Stationarity with stl approach**</u>
```{r stl_monthly_massa, include = TRUE}
ts_watervolume_monthly_stl <- stl(ts_watervolume_monthly, s.window = 24, t.window=365.2422)
remainder_ts_watervolume_monthly_stl <- ts_watervolume_monthly_stl$time.series[,"remainder"]
acf(remainder_ts_watervolume_monthly_stl, main = "ACF of residuals watervolume massa / monthly average / stl")
pacf(remainder_ts_watervolume_monthly_stl, main = "PACF of residuals watervolume massa / monthly average / stl")
plot(remainder_ts_watervolume_monthly_stl, main = "Residuals watervolume massa / monthly average / stl")
adf.test(na.omit(remainder_ts_watervolume_monthly_stl))
plot(ts_watervolume_monthly_stl)
```

<u>**Creating massa stationary dataframe**</u>
```{r stl_monthly_massa_dataframe, include = TRUE}
#Creating dataframe of the prepared data
massa_monthly_mean_stl <- data.frame(
  Date      = as.Date(paste(df_massa_monthly$Year, df_massa_monthly$Month, "01", sep = "-")),  # monthly date
  Original  = as.numeric(ts_watervolume_monthly),                 # original data
  Trend     = ts_watervolume_monthly_stl$time.series[,"trend"],         # trend component
  Seasonal  = ts_watervolume_monthly_stl$time.series[,"seasonal"],      # seasonal component
  Remainder = ts_watervolume_monthly_stl$time.series[,"remainder"]      # remainder
)

head(massa_monthly_mean_stl)  # for checking

# # CSV export
# write.csv(
#   massa_monthly_mean_stl, 
#   "stationary_monthly_mean_watervolume_massa.csv", 
#   row.names = FALSE
# )
# 
# # RDS export
# saveRDS(
#   massa_monthly_mean_stl, 
#   "stationary_monthly_mean_watervolume_massa.rds"
# )
```


# Merge Data
For convenience for further modelling we merged the preprocessed datasets jungfraujoch_temperature, glacier_mass_balance, mass_waterlevel and brig_rain by the date column. Due to different start and end dates we chose to keep the overlapping time period (01/01/1981 to 01/12/2020) in order to get a complete dataset.

<u>**Merge data*</u>
```{r merge_data, include = TRUE}
# laod data
df_jungfrau <- readRDS("../data/processed/jungfraujoch_temperature.rds")
df_glacier <- readRDS("../data/processed/glacier_monthly_processed.rds")
df_waterlevel <- readRDS("../data/processed/waterlevel_det_stoch.rds")
df_precipitation <- readRDS("../data/processed/rain_decomposition.rds")
# convert date columns to identical format
# jungfrau
# Number of rows
n <- nrow(df_jungfrau)

# Create monthly sequence from start year/month
start_date <- as.Date("1933-01-01")
df_jungfrau <- df_jungfrau %>%
  mutate(Date = seq.Date(from = start_date, by = "month", length.out = n))
# glacier
df_glacier <- df_glacier %>%
  mutate(Date = as.Date(year_month))
# waterlevel
# Map German month abbreviations to month numbers
month_map <- c(
  "Jan" = 1, "Feb" = 2, "Mär" = 3, "Apr" = 4,
  "Mai" = 5, "Jun" = 6, "Jul" = 7, "Aug" = 8,
  "Sep" = 9, "Okt" = 10, "Nov" = 11, "Dez" = 12
)

df_waterlevel <- df_waterlevel %>%
  mutate(
    # split year_month into month abbreviation and year
    Month = sapply(strsplit(year_month, " "), `[`, 1),
    Year  = as.numeric(sapply(strsplit(year_month, " "), `[`, 2)),
    Month = month_map[Month],                        # map to numeric month
    Date  = as.Date(paste0(Year, "-", Month, "-01")) # create Date
  ) %>%
  select(-Month, -Year, -year_month)  # remove helper columns
# precipiation
str(df_precipitation) # already in right format

# merge by dates, full outer join
df_merged <- df_jungfrau %>%
  select(Date, observed, trend, seasonal, remainder) %>%
  full_join(df_glacier %>%
              select(Date, mass_balance_monthly, trend, seasonal, deterministic, stochastic),
            by = "Date", suffix = c("_jungfrau", "_glacier")) %>%
  full_join(df_waterlevel %>%
              select(Date, waterlevel_m, trend, seasonal, deterministic, stochastic),
            by = "Date", suffix = c("", "_waterlevel")) %>%
  full_join(df_precipitation %>%
              select(Date, Original, Trend, Seasonal, Remainder),
            by = "Date", suffix = c("", "_precipitation")) %>%
  arrange(Date)

# rename columns
df_merged <- df_merged %>%
  rename(
    # Jungfrau
    observed_jungfrau = observed,
    trend_jungfrau = trend_jungfrau,
    seasonal_jungfrau = seasonal_jungfrau,
    remainder_jungfrau = remainder,
    
    # Glacier
    mass_balance_glacier = mass_balance_monthly,
    trend_glacier = trend_glacier,
    seasonal_glacier = seasonal_glacier,
    deterministic_glacier = deterministic,
    stochastic_glacier = stochastic,
    
    # Waterlevel
    waterlevel = waterlevel_m,
    trend_waterlevel = trend,
    seasonal_waterlevel = seasonal,
    deterministic_waterlevel = deterministic_waterlevel,
    stochastic_waterlevel = stochastic_waterlevel,
    
    # Precipitation
    precipitation = Original,
    trend_precipitation = Trend,
    seasonal_precipitation = Seasonal,
    remainder_precipitation = Remainder
  )

# select same time span
# Find first and last date of each dataset
start_jungfrau <- min(df_merged$Date[!is.na(df_merged$observed_jungfrau)])
end_jungfrau   <- max(df_merged$Date[!is.na(df_merged$observed_jungfrau)])

start_glacier  <- min(df_merged$Date[!is.na(df_merged$mass_balance_glacier)])
end_glacier    <- max(df_merged$Date[!is.na(df_merged$mass_balance_glacier)])

start_water    <- min(df_merged$Date[!is.na(df_merged$waterlevel)])
end_water      <- max(df_merged$Date[!is.na(df_merged$waterlevel)])

start_precip   <- min(df_merged$Date[!is.na(df_merged$precipitation)])
end_precip     <- max(df_merged$Date[!is.na(df_merged$precipitation)])

# Overlapping date range
start_overlap <- max(start_jungfrau, start_glacier, start_water, start_precip)
end_overlap   <- min(end_jungfrau, end_glacier, end_water, end_precip)

df_merged_overlap <- df_merged %>%
  filter(Date >= start_overlap & Date <= end_overlap)

str(df_merged_overlap)
head(df_merged_overlap)
colSums(is.na(df_merged_overlap))
any(is.na(df_merged_overlap)) # no NAs

# create processed data file
write.csv(df_merged_overlap, "../data/processed/df_merged.csv", row.names = FALSE)
# RDS
saveRDS(df_merged_overlap, "../data/processed/df_merged.rds")

```
# Modelling

## Cross-Correlation Analysis
To investigate potential linear relationships between the different time series, we use the cross-correlation function (ccf). For this we only need the stationary remainder components of each time series, since we want to avoid spurious correlations caused by trends and seasonal components. 
<u>**Create dataframe for Cross-Correlation Analysis**</u>
```{r dataframe_ccf, include = TRUE, warning=FALSE, message=FALSE}
# select the columns relevant for cross-correlation analysis
df_ccf <- df_merged_overlap %>%
  select(
    Date,
    remainder_jungfrau,
    remainder_precipitation,
    stochastic_glacier,
    stochastic_waterlevel
  )
# convert back to time series objects
# Number of observations
n <- nrow(df_ccf)
# Create time series objects (monthly frequency)
# Example: temperature and glacier mass balance
start_year <- year(min(df_ccf$Date))
start_month <- month(min(df_ccf$Date))

# Create monthly time series objects
temp_ts <- ts(df_ccf$remainder_jungfrau,
              start = c(start_year, start_month),
              frequency = 12)

glacier_ts <- ts(df_ccf$stochastic_glacier,
                 start = c(start_year, start_month),
                 frequency = 12)
precip_ts <- ts(df_ccf$remainder_precipitation,
                start = c(start_year, start_month),
                frequency = 12)

waterlevel_ts <- ts(df_ccf$stochastic_waterlevel,
                    start = c(start_year, start_month),
                    frequency = 12)
```

When looking at the output of the cross-correlation function between Jungfraujoch temperature and glacier mass balance the correlations are very weak (|r| < 0.3), indicating little to no relationship between the two variables. At a first glance this result surprised us. Yet when considering that the glacier mass balance data originally was bi-annually and we interpolated it to monthly values, the weak correlation became understandable. With the interpolation to monthly values the glacier mass balance data was artificially flattened making it impossible to find any relationship with temperature. The same argumentation applies to the cross-correlation function between glacier mass balance the waterlevel of the river Massa.

<u>**CCF Jungfraujoch Temperature & Glacier Mass Balance**</u>
```{r ccf_jungfraujoch_temperature_glacier_mass_balance, include = TRUE, warning=FALSE, message=FALSE}
temp_scaled <- scale(temp_ts)
glacier_scaled <- scale(glacier_ts)
plot(temp_scaled, type="l", col="orange", lwd=2, ylab="Scaled value", xlab="Time")
lines(glacier_scaled, col="blue", lwd=2)
legend("topright", legend=c("Temperature Jungfraujoch", "Glacier Mass Balance"), col=c("orange","blue"), lty=1)
ccf(glacier_ts, temp_ts) # temperature leads
ccf(temp_ts, glacier_ts) # glacier leads
```
<u>**CCF Glacier Mass Balance & Massa Waterlevel**</u>
```{r ccf_glacier_mass_balance_waterlevel, include = TRUE, warning=FALSE, message=FALSE}
glacier_scaled <- scale(glacier_ts)
waterlevel_scaled <- scale(waterlevel_ts)
plot(glacier_scaled, type="l", col="orange", lwd=2, ylab="Scaled value", xlab="Time")
lines(waterlevel_scaled, col="blue", lwd=2)
legend("topright", legend=c("Glacier Mass Balance", "Waterlevel Massa"), col=c("orange","blue"), lty=1)
ccf(waterlevel_ts, glacier_ts) # glacier leads
ccf(glacier_ts, waterlevel_ts) # waterlevel leads
```
For the cross-correlation function between the Jungfraujoch temperature and the waterlevels Massa we can observe that temperature is leading with significant positive correlations at lags 0, 1 and 3. This is in line with our hypothesis that higher temperatures lead to increased snow melt, which then raises water levels with some delay. The negative correlations at lags 9 and 10 are likely due to the correlation of past high summer temperatures with low winter water levels. 
<u>**CCF Jungfraujoch Temperature & Massa Waterlevel**</u>
```{r ccf_jungfraujoch_temperature_waterlevel, include = TRUE, warning=FALSE, message=FALSE}
temp_scaled <- scale(temp_ts)
waterlevel_scaled <- scale(waterlevel_ts)
plot(temp_scaled, type="l", col="orange", lwd=2, ylab="Scaled value", xlab="Time")
lines(waterlevel_scaled, col="blue", lwd=2)
legend("topright", legend=c("Temperature Jungfraujoch", "Waterlevel Massa"), col=c("orange","blue"), lty=1)
ccf(waterlevel_ts, temp_ts) # temperature leads
ccf(temp_ts, waterlevel_ts) # waterlevel leads
```
The cross-correlation analysis between the monthly precipitations in Brig and the monthly waterlevels of Massa shows no significant relationship. Due to the use of monthly data it is possible that short-term effects were smoothed out. It might also be the case that precipitations in the valley in Brig does not reflect the hdydrological processes in the glacial upstream cachement of the river Massa. In further analysis snow and glacier melt should be taken into account as well. In addition, using the water discharge instead of water level could provide a more direct measure of the river's hydrological response.
<u>**CCF Precipitation Brig & Massa Waterlevel**</u>
```{r ccf_precipitation_waterlevel, include = TRUE, warning=FALSE, message=FALSE}
precip_scaled <- scale(precip_ts)
waterlevel_scaled <- scale(waterlevel_ts)
plot(precip_scaled, type="l", col="orange", lwd=2, ylab="Scaled value", xlab="Time")
lines(waterlevel_scaled, col="blue", lwd=2)
legend("topright", legend=c("Precipitation Brig", "Waterlevel Massa"), col=c("orange","blue"), lty=1)
ccf(waterlevel_ts, precip_ts) # precipitation leads
ccf(precip_ts, waterlevel_ts) # waterlevel leads
```


# Extreme Value Theory (EVT) {#EVT_Massa_Report}

For the EVT analysis, we focus primarily on the Massa River, while the identical data preparation and visualization steps for the Rhone River are provided in the [appendix](#EVT_Rhone_Appendix). As the Rhone is not the core subject of this project, its results are not discussed in detail in the main body of the report.

## River Massa

In this section, we take a closer look at the water discharge of the Massa River, measured in cubic meters per second (m³/s), as it provides a reliable indication of the river’s flow volume.

In addition, there exists a report by the BAG [Hochwasserstatistik - Stationsbericht: Massa - Blatten bei Naters](https://www.hydrodaten.admin.ch/documents/Hochwasserstatistikberichte/2161_hq_Bericht.pdf) addressing the same subject. While their dataset spans the years 1925–2015, our analysis is based on data from 1980–2020.

By comparing the plots, it becomes apparent that the BAG dataset contains many observations exceeding 100 m³/s, whereas our dataset does not surpass this threshold, despite overlapping observation periods. A key difference is that the BAG report is based on daily maximum values, whereas our analysis uses daily mean values.

<u>**Daily maximum water discharge plot of river Massa (Screenshot out of BAG report)**</u>
```{r EVT_bag_report_massa, include = TRUE, warning=FALSE, message=FALSE, out.width="100%"}
knitr::include_graphics('../data/raw/BAG_Massa_Discharge_Plot.png')
```

<u>**Daily mean water discharge plot of river Massa**</u>
```{r EVT_daily_mean_massa, include = TRUE, warning=FALSE, message=FALSE, out.width="100%"}
ggplot(df_massa_prep, aes(x=df_massa_prep$Date, y=df_massa_prep$Watervolume)) +
  geom_point(size = 0.5) +
  labs(
    title = "Water mean discharge of river Massa",
    x = "Date",
    y = "Water Discharge (m³/s)"
  ) +
  theme_minimal()

```

When cross-checking our data with the [Massa – Blatten bei Naters](https://www.hydrodaten.admin.ch/en/seen-und-fluesse/stations/2161#waterlevel-annual) records, which also provide daily mean values, we find identical results, confirming the accuracy and reliability of our dataset.

Due to the differences in data sources and measurement approaches, it is likely that our EVT results will differ from those presented in the BAG report. Nevertheless, the BAG report remains a valuable reference, allowing us to assess whether our findings exhibit similar patterns.

### Histogram of water discharge of river Massa

The histogram exhibits a pronounced right-skewed distribution, which at first glance might seem counterintuitive. This can be attributed to the hydrological regime of the Massa River, which is almost exclusively sustained by glacial meltwater and precipitation within the valley. During the winter season, precipitation is minimal and the glacier contributes no meltwater, leading to extended periods of zero discharge. As a result, the histogram displays a high frequency of zero values. In contrast, the extreme discharge events, which occur only very occasionally during the observation period of 1980-2020, reach values of nearly 100 m³/s.

<u>**EVT Massa Histogram**</u>
```{r EVT_histogram_massa, include = TRUE, warning=FALSE, message=FALSE, out.width="100%"}
# histogram
p_massa <- ggplot(df_massa_prep, aes(x=Watervolume)) + 
  geom_histogram() +
  ggtitle("Histogramm of massa water discharge in m³/s") +
  theme_minimal()
plot(p_massa)
```

### Plotting lm-trend line

By plotting the trend line of the Massa River discharge over the observed period, we can observe a positive trend. When constructing a trend line based only on the upper 95 quantile values, we obtain a very similar trend, differing only in its offset/intercept.

This indicates that the extreme values follow the same long-term trend as the overall data. For Extreme Value Theory (EVT) analysis, this is important because it suggests that the data can be treated as approximately stationary once the trend is accounted for. If the trends differed significantly, it would be necessary to remove the trend from the extreme values before applying EVT to ensure valid modeling of the extremes.

<u>**EVT Massa Data Preparation**</u>
```{r EVT_massa, include = TRUE, warning=FALSE, message=FALSE, out.width="100%"}
# defining trend lm
massa_t_lm <- lm(Watervolume ~ Date, data = df_massa_prep)

# defining trend lm with extrem values
threshold <- quantile(df_massa_prep$Watervolume, 0.95)  # upper 5%-quantile
massa_ex <- subset(df_massa_prep, Watervolume > threshold)

massa_ex_t_lm <- lm(Watervolume ~ Date, data = massa_ex)

# storing lm coef in dataframe
trend_df <- data.frame(
  intercept = c(coef(massa_t_lm)[1], coef(massa_ex_t_lm)[1]),
  slope     = c(coef(massa_t_lm)[2], coef(massa_ex_t_lm)[2]),
  type      = c("Trend with all values", "Trend with extreme values")
)

# Plotting raw data with trend lines
ggplot(df_massa_prep, aes(x = Date, y = Watervolume)) +
  geom_line(color = "black") +
  geom_abline(data = trend_df,
              aes(intercept = intercept, slope = slope, color = type),
              size = 1) +
  labs(title = "Water discharge with trend lines",
       x = "Year", y = expression("m"^3*"/s"),
       color = "Trend type") +
  theme_minimal()
```

### EVT Peaks over Threshold (POT)

By setting the threshold at the upper 0.998 quantile, we obtain 30 observations that align well on the quantile plot, indicating an approximately normal distribution.

The return level plot illustrates and predicts the frequency of extreme events. It also shows that the observed values follow the fitted trend line closely. Since the POT method was applied, the return period is expressed on a daily logistic basis.

The return level plot further suggests that approximately every 1,000 days an extreme event of around 100 m³/s may occur. The curve exhibits a logarithmic-like shape, gradually flattening at a level close to 100 m³/s.


<u>**EVT POT massa**</u>
```{r EVT_modeling_threshold_massa, include = TRUE}
#EVT original data on upper quantil
threshold_massa_evt <- quantile(df_massa_prep$Watervolume, 0.998)
#Amount of observation points
sum(df_massa_prep$Watervolume > threshold_massa_evt)
massa_ex <- df_massa_prep %>% filter(df_massa_prep$Watervolume > threshold_massa_evt)
massa_ex_fit <- gev.fit(massa_ex$Watervolume)
gev.diag(massa_ex_fit) # -> Return Period is on a daily scale
massa_ex_fit$mle
```

### EVT Block Max Year

With the Block Maxima (yearly) method, we consider the maximum water discharge value of each year. When plotted, the resulting quantile plot shows that the observations align closely with the reference line.

The return level plot illustrates and predicts the frequency of extreme events on a yearly scale. Its shape closely resembles that of the POT approach. After approximately 10 years, the curve approaches a value of around 95 m³/s and levels off into a plateau at approximately 100 m³/s, without exceeding it. This suggests that even over a 1,000-year return period, the discharge is unlikely to surpass 100 m³/s.


<u>**EVT Block max year massa**</u>
```{r EVT_modeling_block_max_massa, include = TRUE}
#-----------------
#EVT original data block max year

df_massa_prep <- df_massa_prep %>%
  mutate(Date = massa_start_date + (Date - min(Date)))  # Time as day offset

massa_max_year <- df_massa_prep %>%
  mutate(YEAR = year(Date),
         MONTH = month(Date)) %>%
  group_by(YEAR) %>%
  summarize(Watervolume_MAX = max(Watervolume, na.rm = TRUE)) %>%
  ungroup()

massa_max_year_fit <- gev.fit(massa_max_year$Watervolume_MAX)
gev.diag(massa_max_year_fit) # -> Return Period is on a yearly scale
massa_max_year_fit$mle
```

#### EVT HQ Values

The ‘EVT HQ Block Max Massa’ table provides a clear and easily interpretable overview of the extreme values. It lists the return periods in years and the corresponding HQ values (High-Flood Discharge, Hochwasserkennwert) in m³/s. It corresponds to the Return Level Plot of the Block Max approach.

<u>**EVT HQ block max Massa**</u>
```{r EVT_modeling_hq_massa, include = TRUE}
# Outputting HQ Values
# -> -> Hochwasser-Quantil / Hochwasserabluss: flood quantil for a defined return interval
# -> HQ2 means the watervolume will be achieved/exceeded each 2 years

loc_massa <- massa_max_year_fit$mle[1]
scale_massa <- massa_max_year_fit$mle[2]
shape_massa <- massa_max_year_fit$mle[3]

# return periode in years
return_periods_massa <- c(2, 10, 30, 100, 300)

# probability p = 1 - 1/T
p <- 1 - 1 / return_periods_massa


# calculating HQ-Value
HQ_massa <- qgev(p, loc=loc_massa, scale=scale_massa, shape=shape_massa)

# output
hq_table_massa <- data.frame(ReturnPeriod = return_periods_massa, HQ = HQ_massa)
hq_table_massa
```

### EVT conclusion

Our EVT analysis for the Massa River does not predict any extreme events approaching the “Bemessungshochwasser” of the Gibidum Dam. This indicates that the dam was appropriately dimensioned at the time of its construction and is capable of withstanding future extreme water discharges.

However, as expected, our results differ from the BAG report, which predicts events of up to 150 m³/s (depending on the EVT method used) occurring approximately every 300 years. This difference is primarily due to the BAG analysis being based on daily maximum values, whereas our study uses daily mean values. Consequently, their approach is better suited for capturing the absolute extreme events. Nevertheless, even their estimated extremes remain well below the 450 m³/s design discharge that the Gibidum Dam was engineered to withstand.

Based on these findings, we are confident that the extreme water discharges of the Massa River, as influenced by climate change and its effects on the Aletsch Glacier, do not pose a significant threat in terms of river flow volumes.

What is not addressed in our analysis, however, is the impact of the glacier’s retreat and its associated counterpressure on the valley and surrounding rocks. This may destabilize the ground and trigger landslides, potentially affecting the structural integrity of the dam directly, or indirectly through debris avalanches. Events such as the glacier/rock collapse in Blatten in spring 2025 illustrate how these processes can lead to unpredictable natural disasters.


# Conclusion

# Outlook (Vani)


# Disclaimer for AI


# Appendix

## Feature Explanation of the dataset

### Glacier Data

Winter/Summer/Annual mass balance (Bw/Bs/Ba) → millimeters water equivalent (mm w.e.), representing the amount of snow accumulated in winter/summer/annually converted to the equivalent depth of water. 
The Equilibrium Line Altitude (ELA) -> the elevation on a glacier where annual accumulation equals annual ablation. (If temperatures rise or snowfall decreases, the ELA rises.)
Minimum and maximum elevation of glacier → Determines vertical gradient and exposure to temperature changes.
Accumulation Area Ratio -> Area of Accumulation Zone / Total Glacier Area. It is used as a climate/glacier health indicator. If the AAR is lower (e.g. 0.2), it means the glacier is losing mass and shrinking.

## EVT river Rhone {#EVT_Rhone_Appendix}

[Back to Chapter 'Extreme Value Theory (EVT)'](#EVT_Massa_Report)

### First data analysis rhone

<u>**EVT Rhone Data Preparation**</u>
```{r evt_rhone_preparation, echo=FALSE}
# Read data
df_rhone <- raw_rhone

## Time Series Rhone River - daily data
freq_daily <- 365.2422

ts_watervolume_rhone <- ts(df_rhone$discharge_vol_m3s, 
              start = c(year(min(df_rhone$date_yyyymmdd)),
                        yday(min(df_rhone$date_yyyymmdd))), 
              frequency = freq_daily)


# creating dataframe out of ts_watervolume_rhone 
#----------------------------
# defining start date
rhone_start_date <- as.Date("1981-01-01")
# length of time series
n <- length(ts_watervolume_rhone)
# creating date
rhone_dates <- seq.Date(from = rhone_start_date, by = "day", length.out = n)

df_rhone_prep <- data.frame(
  Date = rhone_dates,
  Watervolume = ts_watervolume_rhone
)

#----------------------------------------------------------------------
#----------------------------------------------------------------------
#First insights of rhone data / creating ts

#plotting rhone data / watervolume
plot(ts_watervolume_rhone, main = "Rhone daily discharge volume in m³/s 1980 - 2020")
```

<u>**EVT Rhone Histogram**</u>
```{r EVT_histogram_rhone, include = TRUE, warning=FALSE, message=FALSE}
# histogram
p_rhone <- ggplot(df_rhone_prep, aes(x=Watervolume)) + 
  geom_histogram() +
  ggtitle("Histogramm of rhone water discharge in m³/s")
plot(p_rhone)
```

### Plotting lm-trend line

<u>**EVT Rhone Data Preparation**</u>
```{r EVT_rhone, include = TRUE, warning=FALSE, message=FALSE}
# defining trend lm
rhone_t_lm <- lm(Watervolume ~ Date, data = df_rhone_prep)

# defining trend lm with extrem values
threshold <- quantile(df_rhone_prep$Watervolume, 0.95)  # upper 5%-quantile
rhone_ex <- subset(df_rhone_prep, Watervolume > threshold)

rhone_ex_t_lm <- lm(Watervolume ~ Date, data = rhone_ex)

# storing lm coef in dataframe
trend_df <- data.frame(
  intercept = c(coef(rhone_t_lm)[1], coef(rhone_ex_t_lm)[1]),
  slope     = c(coef(rhone_t_lm)[2], coef(rhone_ex_t_lm)[2]),
  type      = c("Trend with all values", "Trend with extreme values")
)

# Plotting raw data with trend lines
ggplot(df_rhone_prep, aes(x = Date, y = Watervolume)) +
  geom_line(color = "black") +
  geom_abline(data = trend_df,
              aes(intercept = intercept, slope = slope, color = type),
              size = 1) +
  labs(title = "Water discharge with trend lines",
       x = "Year", y = expression("m"^3*"/s"),
       color = "Trend type") +
  theme_minimal()
```


### EVT Peaks over Threshold (POT)

<u>**EVT POT Rhone**</u>
```{r EVT_modeling_threshold_rhone, include = TRUE}
#EVT original data on upper quantil
threshold_rhone_evt <- quantile(df_rhone_prep$Watervolume, 0.998)
rhone_ex <- df_rhone_prep %>% filter(df_rhone_prep$Watervolume > threshold_rhone_evt)
rhone_ex_fit <- gev.fit(rhone_ex$Watervolume)
gev.diag(rhone_ex_fit) # -> Return Period is on a daily scale
rhone_ex_fit$mle
```

### EVT Block Max Year 

<u>**EVT Block max year Rhone**</u>
```{r EVT_modeling_block_max_rhone, include = TRUE}
#-----------------
#EVT original data block max year

df_rhone_prep <- df_rhone_prep %>%
  mutate(Date = rhone_start_date + (Date - min(Date)))  # Time as day offset

rhone_max_year <- df_rhone_prep %>%
  mutate(YEAR = year(Date),
         MONTH = month(Date)) %>%
  group_by(YEAR) %>%
  summarize(Watervolume_MAX = max(Watervolume, na.rm = TRUE)) %>%
  ungroup()

rhone_max_year_fit <- gev.fit(rhone_max_year$Watervolume_MAX)
gev.diag(rhone_max_year_fit) # -> Return Period is on a yearly scale
rhone_max_year_fit$mle
```

### EVT HQ Values

<u>**EVT HQ block max Rhone**</u>
```{r EVT_modeling_hq_rhone, include = TRUE}
# Outputting HQ Values
# -> -> Hochwasser-Quantil / Hochwasserabluss: flood quantil for a defined return interval
# -> HQ2 means the watervolume will be achieved/exceeded each 2 years

loc_rhone <- rhone_max_year_fit$mle[1]
scale_rhone <- rhone_max_year_fit$mle[2]
shape_rhone <- rhone_max_year_fit$mle[3]

# return periode in years
return_periods_rhone <- c(2, 10, 30, 100, 300)

# probability p = 1 - 1/T
p <- 1 - 1 / return_periods_rhone


# calculating HQ-Value
HQ_rhone <- qgev(p, loc=loc_rhone, scale=scale_rhone, shape=shape_rhone)

# output
hq_table_rhone <- data.frame(ReturnPeriod = return_periods_rhone, HQ = HQ_rhone)
hq_table_rhone
```